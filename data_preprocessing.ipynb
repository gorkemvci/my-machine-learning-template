{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "We add the libraries to be used.\n",
        "We are reading the data from csv file with the help of pandas.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H4mgtGMlHM4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "#upload data\n",
        "data = pd.read_csv(\"data.csv\")\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "48HOCWTwbuK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversion of Categorical Data\n",
        "Secondly, we transform the categorical data in our dataset into numerical data. So they will be usable for Regression analysis.\n",
        "While LabelEncoder is used for binary categorical data, it is wiser to use OneHotEncoder for more than 2 categorical data. Because this will make it easier for the computer to understand."
      ],
      "metadata": {
        "id": "aKQeRTe4IatD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#label encoder\n",
        "country = data.iloc[:,0:1].values\n",
        "lbl_cdr = preprocessing.LabelEncoder()\n",
        "country[:,0] = lbl_cdr.fit_transform(data.iloc[:,0])\n",
        "print(country)\n",
        "#onehotencoder\n",
        "ohot_cdr = preprocessing.OneHotEncoder()\n",
        "country = ohot_cdr.fit_transform(country).toarray()\n",
        "print(country)"
      ],
      "metadata": {
        "id": "99TTW7IpcB9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining edited data into a dataset\n",
        "We combine the categorical data that we converted to numeric value with other columns in a new dataset. We use the pandas library for this."
      ],
      "metadata": {
        "id": "EW1LP3pAKhLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transform dataframe\n",
        "#divide by independent variable and dependent variable\n",
        "info_clmn =data.iloc[:,1:-1].values\n",
        "counrty_df = pd.DataFrame(data=country , index = range(17), columns = [\"fr\", \"tr\", \"us\"])\n",
        "print(counrty_df )\n",
        "info_df = pd.DataFrame(data=info_clmn , index = range(17), columns = [\"height\", \" weight\", \"age\"])\n",
        "print(info_df)\n",
        "gender = data.iloc[:,-1]\n",
        "print(gender)\n",
        "independent_v= pd.concat([counrty_df,info_df], axis= 1)\n",
        "print(independent_v)\n"
      ],
      "metadata": {
        "id": "9Kn5pZ3GdZOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardization\n",
        "Here we apply standardization to our data with the help of StandardScaler(). This will make the calculations of some prediction algorithms easier."
      ],
      "metadata": {
        "id": "o0ZSvz1-Lp6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "standart_data = sc.fit_transform(independent_v)\n",
        "print(standart_data)"
      ],
      "metadata": {
        "id": "Df19NXW7mkaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the dataset for training\n",
        "We divide our data into x_train, x_test , y_train , y_test as test_size 0.20.\n",
        "1.   Dividing as test_size = 0.20 means that 4 out of every five data will be used for training and 1 will be used for testing.\n",
        "2. You can change the test_size value. For example: 0.33, 0.5, 0.25.\n",
        "\n"
      ],
      "metadata": {
        "id": "CC7sUQUHN9fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#separate train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test , y_train , y_test = train_test_split(independent_v,gender,test_size=0.20, random_state=0)\n",
        "print(x_train)\n",
        "print(y_train)\n",
        "print(x_test)\n",
        "print(y_test)"
      ],
      "metadata": {
        "id": "KmZ-cjsegcDu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}