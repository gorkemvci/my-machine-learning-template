{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "\n",
        "*   Sigmoid Step Function\n",
        "*   1/ 1+e^-t\n",
        "\n"
      ],
      "metadata": {
        "id": "aZCZWa_Ms6rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "We add the libraries to be used.\n",
        "We are reading the data from csv file with the help of pandas.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S9Lu-cF7zPzr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_hhghYzK4ZsH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv(\"data.csv\")\n",
        "x = data.iloc[:,1:4]\n",
        "y = data.iloc[:,-1:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardization\n",
        "Here we apply standardization to our data with the help of StandardScaler(). This will make the calculations of logistic algorithm easier."
      ],
      "metadata": {
        "id": "0XE8znvovh_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_all = sc.fit_transform(x)\n",
        "#print(x_all)"
      ],
      "metadata": {
        "id": "SbQL5xxFJobH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the dataset for training\n",
        "We divide our data into x_train, x_test , y_train , y_test as test_size 0.33."
      ],
      "metadata": {
        "id": "oeH3Xw7_v6LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train , x_test , y_train , y_test = train_test_split(x_all,y,test_size=0.33, random_state = 0)\n"
      ],
      "metadata": {
        "id": "v78WX9UzKYCv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "npfYTsQBv_-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_r = LogisticRegression(random_state=0)\n",
        "log_r.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "3IhVcX21KD29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results of Logistic Regression Model"
      ],
      "metadata": {
        "id": "nC_7TDULwFxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred=log_r.predict(x_test)\n",
        "print(pred)\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPQva93PTGyp",
        "outputId": "d22df1b2-a35d-4ce1-a7e4-88dc9fa47481"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['man' 'woman' 'woman' 'woman' 'man' 'man']\n",
            "    gender\n",
            "1      man\n",
            "6    woman\n",
            "8    woman\n",
            "9    woman\n",
            "13     man\n",
            "4      man\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix\n",
        "Confusion matrix is a matrix used to evaluate the performance of a classification model by comparing the actual and predicted classes, helping to calculate the accuracy and other performance metrics of the model."
      ],
      "metadata": {
        "id": "AMzalyGmw5we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "con_mx = confusion_matrix(pred,y_test)\n",
        "print(con_mx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At7dKOI4VXfL",
        "outputId": "fc0559a3-702f-4337-f1f1-468f74881b45"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3 0]\n",
            " [0 3]]\n"
          ]
        }
      ]
    }
  ]
}